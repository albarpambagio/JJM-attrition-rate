{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c76aff",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "04 Modeling\n",
    "Train and evaluate models for employee attrition prediction.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a635cca",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from src.modeling import setup_modeling, train_and_tune_model, evaluate_trained_model, plot_feature_importance, save_trained_model\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, precision_recall_curve\n",
    "import numpy as np\n",
    "import os\n",
    "from pycaret.classification import predict_model, plot_model, pull\n",
    "import shutil\n",
    "import shap\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4a4e87",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "display(Markdown(\"\"\"\n",
    "# Modeling\n",
    "This notebook trains and evaluates machine learning models to predict employee attrition.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a484055",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "display(Markdown(\"\"\"\n",
    "## Load Engineered Features\n",
    "We load the dataset with engineered features for modeling.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c59fdc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Load engineered features\n",
    "features_df = pd.read_csv('data/employee_data_features.csv')\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18fde7a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "display(Markdown(\"\"\"\n",
    "## Preprocess Categorical Columns\n",
    "We preprocess categorical variables to ensure they are in a suitable format for modeling.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc69eccd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Preprocess categorical columns for modeling (if needed)\n",
    "categorical_cols = ['BusinessTravel', 'Department', 'EducationField', \n",
    "                   'Gender', 'JobRole', 'MaritalStatus', 'Over18', 'OverTime', 'AgeGroup']\n",
    "for col in categorical_cols:\n",
    "    features_df[col] = features_df[col].astype(str).str.replace(' ', '_').str.replace('&', '_and_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e1431c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "display(Markdown(\"\"\"\n",
    "## Setup Modeling Environment\n",
    "We initialize the modeling environment, including data splitting and preprocessing.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc0714",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Setup modeling environment\n",
    "setup_modeling(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f5ed87",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "display(Markdown(\"\"\"\n",
    "## Train and Tune Model\n",
    "We train and tune a machine learning model to optimize for recall (catching as many attrition cases as possible).\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a891d1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Train and tune model\n",
    "model = train_and_tune_model(model_name='lda', optimize='Recall', n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8987bb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "display(Markdown(\"\"\"\n",
    "## Evaluate Model\n",
    "We evaluate the trained model's performance using relevant metrics.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35baf33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "evaluate_trained_model(model)\n",
    "\n",
    "# Save model\n",
    "model_path = save_trained_model(model, 'models/final_lda_model')\n",
    "# PyCaret appends .pkl if not present\n",
    "if not os.path.exists('models/final_lda_model.pkl'):\n",
    "    print(\"WARNING: Model file models/final_lda_model.pkl not found after saving.\")\n",
    "else:\n",
    "    print(\"Model saved as models/final_lda_model.pkl\")\n",
    "\n",
    "# Export confusion matrix and classification report\n",
    "try:\n",
    "    if hasattr(model, 'predict'):\n",
    "        y_true = features_df['Attrition'] if 'Attrition' in features_df.columns else None\n",
    "        preds_df = predict_model(model, data=features_df)\n",
    "        y_pred = preds_df['Label'] if 'Label' in preds_df.columns else None\n",
    "        if y_true is not None and y_pred is not None:\n",
    "            cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
    "            cr = classification_report(y_true, y_pred)\n",
    "            os.makedirs('results', exist_ok=True)\n",
    "            with open('results/confusion_matrix.md', 'w') as f:\n",
    "                f.write('# Confusion Matrix\\n')\n",
    "                f.write(str(cm))\n",
    "            with open('results/classification_report.md', 'w') as f:\n",
    "                f.write('# Classification Report\\n')\n",
    "                f.write(cr)\n",
    "            # ROC and PR curve data (if binary)\n",
    "            if len(np.unique(y_true)) == 2:\n",
    "                y_score = preds_df['Score'] if 'Score' in preds_df.columns else None\n",
    "                if y_score is not None:\n",
    "                    fpr, tpr, _ = roc_curve(y_true, y_score, pos_label=np.unique(y_true)[1])\n",
    "                    precision, recall, _ = precision_recall_curve(y_true, y_score, pos_label=np.unique(y_true)[1])\n",
    "                    np.savetxt('results/roc_curve.csv', np.column_stack([fpr, tpr]), delimiter=',', header='fpr,tpr', comments='')\n",
    "                    np.savetxt('results/pr_curve.csv', np.column_stack([precision, recall]), delimiter=',', header='precision,recall', comments='')\n",
    "            # Save predictions for consistency\n",
    "            preds_df.to_csv('results/predictions.csv', index=False)\n",
    "        else:\n",
    "            print(\"WARNING: y_true or y_pred is None. Confusion matrix not exported.\")\n",
    "    else:\n",
    "        print(\"WARNING: Model does not have a 'predict' attribute. Confusion matrix not exported.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR exporting confusion matrix: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0baa48c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "display(Markdown(\"\"\"\n",
    "## Feature Importance\n",
    "We analyze which features are most influential in predicting attrition.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c43738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SHAP summary plot and CSV export ---\n",
    "from pycaret.classification import get_config\n",
    "\n",
    "# Get the transformed training data used by PyCaret\n",
    "X_train_transformed = get_config('X_train_transformed')\n",
    "\n",
    "# Create a SHAP explainer for your model\n",
    "explainer = shap.Explainer(model, X_train_transformed)\n",
    "shap_values = explainer(X_train_transformed)\n",
    "\n",
    "# Generate and save SHAP summary plot\n",
    "shap.summary_plot(shap_values.values, X_train_transformed, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/shap_summary_plot.png', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# SHAP feature importance (mean absolute SHAP value per feature)\n",
    "shap_importance = pd.DataFrame({\n",
    "    'Feature': X_train_transformed.columns,\n",
    "    'MeanAbsSHAP': np.abs(shap_values.values).mean(axis=0)\n",
    "}).sort_values(by='MeanAbsSHAP', ascending=False)\n",
    "shap_importance.to_csv('results/shap_feature_importance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6906c7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "display(Markdown(\"\"\"\n",
    "## Save Model\n",
    "The final trained model is saved for future inference and deployment.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c7db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "save_trained_model(model, 'models/final_lda_model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815bd9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"\"\"\n",
    "## Model Performance Insights\n",
    "\n",
    "### Feature Importance & Model Performance\n",
    "- **Model Used:** Linear Discriminant Analysis (LDA)\n",
    "- **Performance:** Accuracy: 70%, AUC: 0.78, Recall: 0.75 (good for catching attrition cases), Precision: 0.34 (many false positives)\n",
    "- **Key Features (by SHAP importance):**\n",
    "    1. **OverTime** â€” Most influential; employees who work overtime are much more likely to leave.\n",
    "    2. **EnvironmentSatisfaction** â€” Lower satisfaction increases attrition risk.\n",
    "    3. **Age** â€” Younger employees tend to have higher attrition risk.\n",
    "    4. **MonthlyIncome** â€” Lower income is associated with higher attrition.\n",
    "    5. **DailyRate, DistanceFromHome, RoleStability, MonthlyRate** â€” These also contribute, but to a lesser extent.\n",
    "\n",
    "#### SHAP Feature Importance Analysis\n",
    "The table below (from `shap_feature_importance.csv`) shows the mean absolute SHAP value for each feature, which quantifies the average impact of each feature on the model's prediction for employee attrition. A higher value means the feature has a greater influence on the model's output.\n",
    "\n",
    "| Rank | Feature                 | MeanAbsSHAP |\n",
    "|------|-------------------------|-------------|\n",
    "| 1    | OverTime                | 0.75        |\n",
    "| 2    | EnvironmentSatisfaction | 0.56        |\n",
    "| 3    | Age                     | 0.37        |\n",
    "| 4    | MonthlyIncome           | 0.26        |\n",
    "| 5    | DailyRate               | 0.20        |\n",
    "| 6    | DistanceFromHome        | 0.19        |\n",
    "| 7    | RoleStability           | 0.16        |\n",
    "| 8    | MonthlyRate             | 0.15        |\n",
    "\n",
    "**Interpretation:**\n",
    "- **OverTime** is by far the most important feature, with a mean absolute SHAP value of 0.75. This means that whether or not an employee works overtime has the largest average effect on the model's prediction of attrition.\n",
    "- **EnvironmentSatisfaction** is the second most important, indicating that employees' satisfaction with their work environment is a key driver of attrition risk.\n",
    "- **Age** is also significant, suggesting that attrition risk varies notably with employee age (often, younger employees are more likely to leave).\n",
    "- **MonthlyIncome** and **DailyRate** both have moderate influence, showing that compensation factors play a role, but are less critical than overtime or satisfaction.\n",
    "- **DistanceFromHome**, **RoleStability**, and **MonthlyRate** have smaller but still meaningful impacts.\n",
    "\n",
    "**Actionable Insights:**\n",
    "- **Monitor and manage overtime:** Since overtime is the top driver, reducing excessive overtime or compensating for it may help reduce attrition.\n",
    "- **Improve environment satisfaction:** Initiatives to boost workplace satisfaction could have a strong effect on retention.\n",
    "- **Targeted retention for younger employees:** Since age is a key factor, consider tailored retention programs for younger staff.\n",
    "- **Review compensation and stability:** While not the top factors, fair pay and stable roles still contribute to retention and should not be neglected.\n",
    "\n",
    "## Modeling Recommendations\n",
    "2. **Modeling Improvements:**\n",
    "   - While recall is high, precision is low. Consider:\n",
    "     - Collecting more data to balance class distribution\n",
    "     - Engineering interaction features between key variables\n",
    "     - Experimenting with alternative models (XGBoost, Random Forest)\n",
    "     - Adjusting classification decision thresholds\n",
    "     - Implementing feature selection to reduce noise\n",
    "\"\"\"))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
