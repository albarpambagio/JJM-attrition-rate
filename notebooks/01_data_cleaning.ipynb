{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fa1bd8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "01 Data Cleaning\n",
    "Load and clean the employee attrition dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600e08ab",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from src.data_processing import load_data, clean_data, split_data\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7707688",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "display(Markdown(\"\"\"\n",
    "# Data Cleaning\n",
    "This notebook loads and cleans the raw employee attrition dataset, preparing it for analysis and modeling.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30904a9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "raw_df = load_data('data/employee_data.csv')\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7181c9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "display(Markdown(\"\"\"\n",
    "## Load Raw Data\n",
    "We begin by loading the raw dataset to inspect its structure and contents.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e436177",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Clean data\n",
    "clean_df = clean_data(raw_df)\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bbb9ed",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "display(Markdown(\"\"\"\n",
    "## Clean Data\n",
    "We apply cleaning steps to handle missing values, correct data types, and fix inconsistencies.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a06b55",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Optionally, split data for modeling and inference\n",
    "model_df, infer_df = split_data(clean_df)\n",
    "print(f\"Modeling set: {model_df.shape}, Inference set: {infer_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec513566",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "display(Markdown(\"\"\"\n",
    "## Split Data (Optional)\n",
    "We optionally split the cleaned data into modeling and inference sets for downstream tasks.\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d64306",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Save cleaned data for next steps\n",
    "clean_df.to_csv('data/employee_data_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd25eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"\"\"\n",
    "## Save Cleaned Data\n",
    "The cleaned dataset is saved for use in EDA and modeling notebooks.\n",
    "\"\"\")) "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
